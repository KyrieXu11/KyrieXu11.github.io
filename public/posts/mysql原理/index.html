<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Secret Room of KyrieXu11</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="执行结构 总体分为两个部分：
server 和 执行引擎
server 连接器-&gt;分析器-&gt;优化器-&gt;执行器。
连接器：负责管理连接。超时断开、用户密码校验。
分析器：词法分析。
优化器：优化查询。
执行器：执行语句，权限校验。
执行引擎 常见的有innodb和myaism。
redolog和binlog redolog redolog为innodb实现的。
对数据库做的更新操作不直接写入磁盘，而是通过write ahead log的技术写入redolog。在空闲的时候，把redolog中的改动同步到磁盘。
图源：https://blog.csdn.net/weixin_43213517/article/details/117457184
为什么需要redolog？ innodb是以页的方式来管理存储空间的，在进行增删改的时候，需要把记录所在的整个页加载到buffer pool（内存）中，在内存做完写操作之后，再进行刷盘，刷盘为随机IO，开销太大。
redolog如何持久化 刷盘时机 后台定时刷盘。 用户commit时。 两个指针 write position和checkpoint。
redolog为环形log，当wp追上了checkpoint，就要刷盘了，这个时候把checkpoint往前推进，才可以继续写。
binlog binlog为server的日志，不归属任何执行引擎，所有执行引擎都可以用。
和redolog有几点不同：
binlog为逻辑日志，而redolog为物理日志。binlog会记录下“给哪一行更新id=2”，而redolog会记录下“在哪个数据页的哪一行进行修改”。 redolog循环写，空间会用完，binlog为追加写，理论上无限大。 两阶段写 总体和分布式事务一个思想，以更新为例子：
执行器找执行引擎取目标记录，执行引擎用树来找这一条记录，如果在内存则直接返回，如果不在内存，则将该记录所在的整个页加载到内存，再返回。 执行器在内存更新完成该记录，再调用引擎的接口写入这行数据。 执行引擎在内存中更新这条数据，并且把更新记录写入redolog，把redolog的状态置为prepare状态，并且告知执行器可以写binlog。 执行器写binlog，把binlog写入磁盘。 执行器再调用执行引擎的接口把redolog的状态改为commit。 如果在写的时候出现的crash，该怎么恢复？
如果redolog中的事务是完整的（有commit标识），则直接commit。 如果redolog只有prepare，则去看binlog事务是否完整。 如果binlog存在事务并且完整，则改redolog为commit，然后commit事务。 如果binlog事务不完整，则直接回滚。 事务 事务会出现的问题 脏读（读取未提交数据）
不可重复读（前后多次读取，数据内容不一致）
幻读（前后多次读取，数据总量不一致）
简单给个实例：
A B start transaction with consistent snapshot select * from t0; // 没有id为4的行 insert into t0(id, k) values(4,4);// 插入成功 insert into t0(id, k) values(4,4); // 报错了。ERROR 1062 (23000): Duplicate entry &lsquo;4&rsquo; for key &rsquo;t0.">
    <meta name="generator" content="Hugo 0.102.0-DEV" />
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    

    
<link rel="stylesheet" href="/ananke/css/main.min.css" >



    
    
    
      

    

    
    
    <meta property="og:title" content="" />
<meta property="og:description" content="执行结构 总体分为两个部分：
server 和 执行引擎
server 连接器-&gt;分析器-&gt;优化器-&gt;执行器。
连接器：负责管理连接。超时断开、用户密码校验。
分析器：词法分析。
优化器：优化查询。
执行器：执行语句，权限校验。
执行引擎 常见的有innodb和myaism。
redolog和binlog redolog redolog为innodb实现的。
对数据库做的更新操作不直接写入磁盘，而是通过write ahead log的技术写入redolog。在空闲的时候，把redolog中的改动同步到磁盘。
图源：https://blog.csdn.net/weixin_43213517/article/details/117457184
为什么需要redolog？ innodb是以页的方式来管理存储空间的，在进行增删改的时候，需要把记录所在的整个页加载到buffer pool（内存）中，在内存做完写操作之后，再进行刷盘，刷盘为随机IO，开销太大。
redolog如何持久化 刷盘时机 后台定时刷盘。 用户commit时。 两个指针 write position和checkpoint。
redolog为环形log，当wp追上了checkpoint，就要刷盘了，这个时候把checkpoint往前推进，才可以继续写。
binlog binlog为server的日志，不归属任何执行引擎，所有执行引擎都可以用。
和redolog有几点不同：
binlog为逻辑日志，而redolog为物理日志。binlog会记录下“给哪一行更新id=2”，而redolog会记录下“在哪个数据页的哪一行进行修改”。 redolog循环写，空间会用完，binlog为追加写，理论上无限大。 两阶段写 总体和分布式事务一个思想，以更新为例子：
执行器找执行引擎取目标记录，执行引擎用树来找这一条记录，如果在内存则直接返回，如果不在内存，则将该记录所在的整个页加载到内存，再返回。 执行器在内存更新完成该记录，再调用引擎的接口写入这行数据。 执行引擎在内存中更新这条数据，并且把更新记录写入redolog，把redolog的状态置为prepare状态，并且告知执行器可以写binlog。 执行器写binlog，把binlog写入磁盘。 执行器再调用执行引擎的接口把redolog的状态改为commit。 如果在写的时候出现的crash，该怎么恢复？
如果redolog中的事务是完整的（有commit标识），则直接commit。 如果redolog只有prepare，则去看binlog事务是否完整。 如果binlog存在事务并且完整，则改redolog为commit，然后commit事务。 如果binlog事务不完整，则直接回滚。 事务 事务会出现的问题 脏读（读取未提交数据）
不可重复读（前后多次读取，数据内容不一致）
幻读（前后多次读取，数据总量不一致）
简单给个实例：
A B start transaction with consistent snapshot select * from t0; // 没有id为4的行 insert into t0(id, k) values(4,4);// 插入成功 insert into t0(id, k) values(4,4); // 报错了。ERROR 1062 (23000): Duplicate entry &lsquo;4&rsquo; for key &rsquo;t0." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://kyriexu11.github.io/posts/mysql%E5%8E%9F%E7%90%86/" /><meta property="article:section" content="posts" />



<meta itemprop="name" content="">
<meta itemprop="description" content="执行结构 总体分为两个部分：
server 和 执行引擎
server 连接器-&gt;分析器-&gt;优化器-&gt;执行器。
连接器：负责管理连接。超时断开、用户密码校验。
分析器：词法分析。
优化器：优化查询。
执行器：执行语句，权限校验。
执行引擎 常见的有innodb和myaism。
redolog和binlog redolog redolog为innodb实现的。
对数据库做的更新操作不直接写入磁盘，而是通过write ahead log的技术写入redolog。在空闲的时候，把redolog中的改动同步到磁盘。
图源：https://blog.csdn.net/weixin_43213517/article/details/117457184
为什么需要redolog？ innodb是以页的方式来管理存储空间的，在进行增删改的时候，需要把记录所在的整个页加载到buffer pool（内存）中，在内存做完写操作之后，再进行刷盘，刷盘为随机IO，开销太大。
redolog如何持久化 刷盘时机 后台定时刷盘。 用户commit时。 两个指针 write position和checkpoint。
redolog为环形log，当wp追上了checkpoint，就要刷盘了，这个时候把checkpoint往前推进，才可以继续写。
binlog binlog为server的日志，不归属任何执行引擎，所有执行引擎都可以用。
和redolog有几点不同：
binlog为逻辑日志，而redolog为物理日志。binlog会记录下“给哪一行更新id=2”，而redolog会记录下“在哪个数据页的哪一行进行修改”。 redolog循环写，空间会用完，binlog为追加写，理论上无限大。 两阶段写 总体和分布式事务一个思想，以更新为例子：
执行器找执行引擎取目标记录，执行引擎用树来找这一条记录，如果在内存则直接返回，如果不在内存，则将该记录所在的整个页加载到内存，再返回。 执行器在内存更新完成该记录，再调用引擎的接口写入这行数据。 执行引擎在内存中更新这条数据，并且把更新记录写入redolog，把redolog的状态置为prepare状态，并且告知执行器可以写binlog。 执行器写binlog，把binlog写入磁盘。 执行器再调用执行引擎的接口把redolog的状态改为commit。 如果在写的时候出现的crash，该怎么恢复？
如果redolog中的事务是完整的（有commit标识），则直接commit。 如果redolog只有prepare，则去看binlog事务是否完整。 如果binlog存在事务并且完整，则改redolog为commit，然后commit事务。 如果binlog事务不完整，则直接回滚。 事务 事务会出现的问题 脏读（读取未提交数据）
不可重复读（前后多次读取，数据内容不一致）
幻读（前后多次读取，数据总量不一致）
简单给个实例：
A B start transaction with consistent snapshot select * from t0; // 没有id为4的行 insert into t0(id, k) values(4,4);// 插入成功 insert into t0(id, k) values(4,4); // 报错了。ERROR 1062 (23000): Duplicate entry &lsquo;4&rsquo; for key &rsquo;t0.">

<meta itemprop="wordCount" content="326">
<meta itemprop="keywords" content="" /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content=""/>
<meta name="twitter:description" content="执行结构 总体分为两个部分：
server 和 执行引擎
server 连接器-&gt;分析器-&gt;优化器-&gt;执行器。
连接器：负责管理连接。超时断开、用户密码校验。
分析器：词法分析。
优化器：优化查询。
执行器：执行语句，权限校验。
执行引擎 常见的有innodb和myaism。
redolog和binlog redolog redolog为innodb实现的。
对数据库做的更新操作不直接写入磁盘，而是通过write ahead log的技术写入redolog。在空闲的时候，把redolog中的改动同步到磁盘。
图源：https://blog.csdn.net/weixin_43213517/article/details/117457184
为什么需要redolog？ innodb是以页的方式来管理存储空间的，在进行增删改的时候，需要把记录所在的整个页加载到buffer pool（内存）中，在内存做完写操作之后，再进行刷盘，刷盘为随机IO，开销太大。
redolog如何持久化 刷盘时机 后台定时刷盘。 用户commit时。 两个指针 write position和checkpoint。
redolog为环形log，当wp追上了checkpoint，就要刷盘了，这个时候把checkpoint往前推进，才可以继续写。
binlog binlog为server的日志，不归属任何执行引擎，所有执行引擎都可以用。
和redolog有几点不同：
binlog为逻辑日志，而redolog为物理日志。binlog会记录下“给哪一行更新id=2”，而redolog会记录下“在哪个数据页的哪一行进行修改”。 redolog循环写，空间会用完，binlog为追加写，理论上无限大。 两阶段写 总体和分布式事务一个思想，以更新为例子：
执行器找执行引擎取目标记录，执行引擎用树来找这一条记录，如果在内存则直接返回，如果不在内存，则将该记录所在的整个页加载到内存，再返回。 执行器在内存更新完成该记录，再调用引擎的接口写入这行数据。 执行引擎在内存中更新这条数据，并且把更新记录写入redolog，把redolog的状态置为prepare状态，并且告知执行器可以写binlog。 执行器写binlog，把binlog写入磁盘。 执行器再调用执行引擎的接口把redolog的状态改为commit。 如果在写的时候出现的crash，该怎么恢复？
如果redolog中的事务是完整的（有commit标识），则直接commit。 如果redolog只有prepare，则去看binlog事务是否完整。 如果binlog存在事务并且完整，则改redolog为commit，然后commit事务。 如果binlog事务不完整，则直接回滚。 事务 事务会出现的问题 脏读（读取未提交数据）
不可重复读（前后多次读取，数据内容不一致）
幻读（前后多次读取，数据总量不一致）
简单给个实例：
A B start transaction with consistent snapshot select * from t0; // 没有id为4的行 insert into t0(id, k) values(4,4);// 插入成功 insert into t0(id, k) values(4,4); // 报错了。ERROR 1062 (23000): Duplicate entry &lsquo;4&rsquo; for key &rsquo;t0."/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        Secret Room of KyrieXu11
      
    </a>
    <div class="flex-l items-center">
      

      
      
<div class="ananke-socials">
  
</div>

    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        POSTS
      </aside>
      










  <div id="sharing" class="mt3 ananke-socials">
    
  </div>


      <h1 class="f1 athelas mt3 mb1"></h1>
      
      
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><h1 id="执行结构">执行结构</h1>
<p>总体分为两个部分：</p>
<p>server 和 执行引擎</p>
<h2 id="server">server</h2>
<p>连接器-&gt;分析器-&gt;优化器-&gt;执行器。</p>
<p>连接器：负责管理连接。超时断开、用户密码校验。</p>
<p>分析器：词法分析。</p>
<p>优化器：优化查询。</p>
<p>执行器：执行语句，权限校验。</p>
<h2 id="执行引擎">执行引擎</h2>
<p>常见的有innodb和myaism。</p>
<h1 id="redolog和binlog">redolog和binlog</h1>
<h2 id="redolog">redolog</h2>
<p>redolog为innodb实现的。</p>
<p>对数据库做的更新操作不直接写入磁盘，而是通过write ahead log的技术写入redolog。在空闲的时候，把redolog中的改动同步到磁盘。</p>
<p>图源：https://blog.csdn.net/weixin_43213517/article/details/117457184</p>
<p><img src=".%5Cinnodb_redolog.png" alt="innodb_redolog"></p>
<h3 id="为什么需要redolog">为什么需要redolog？</h3>
<p>innodb是以页的方式来管理存储空间的，在进行增删改的时候，需要把记录所在的整个页加载到buffer pool（内存）中，在内存做完写操作之后，再进行刷盘，刷盘为随机IO，开销太大。</p>
<h3 id="redolog如何持久化">redolog如何持久化</h3>
<h4 id="刷盘时机">刷盘时机</h4>
<ol>
<li>后台定时刷盘。</li>
<li>用户commit时。</li>
</ol>
<h4 id="两个指针">两个指针</h4>
<p>write position和checkpoint。</p>
<p>redolog为环形log，当wp追上了checkpoint，就要刷盘了，这个时候把checkpoint往前推进，才可以继续写。</p>
<h2 id="binlog">binlog</h2>
<p>binlog为server的日志，不归属任何执行引擎，所有执行引擎都可以用。</p>
<p>和redolog有几点不同：</p>
<ol>
<li>binlog为逻辑日志，而redolog为物理日志。binlog会记录下“给哪一行更新id=2”，而redolog会记录下“在哪个数据页的哪一行进行修改”。</li>
<li>redolog循环写，空间会用完，binlog为追加写，理论上无限大。</li>
</ol>
<h2 id="两阶段写">两阶段写</h2>
<p>总体和分布式事务一个思想，以更新为例子：</p>
<ol>
<li>执行器找执行引擎取目标记录，执行引擎用树来找这一条记录，如果在内存则直接返回，如果不在内存，则将该记录所在的整个页加载到内存，再返回。</li>
<li>执行器在内存更新完成该记录，再调用引擎的接口写入这行数据。</li>
<li>执行引擎在内存中更新这条数据，并且把更新记录写入redolog，把redolog的状态置为prepare状态，并且告知执行器可以写binlog。</li>
<li>执行器写binlog，把binlog写入磁盘。</li>
<li>执行器再调用执行引擎的接口把redolog的状态改为commit。</li>
</ol>
<p>如果在写的时候出现的crash，该怎么恢复？</p>
<ol>
<li>如果redolog中的事务是完整的（有commit标识），则直接commit。</li>
<li>如果redolog只有prepare，则去看binlog事务是否完整。</li>
</ol>
<ul>
<li>如果binlog存在事务并且完整，则改redolog为commit，然后commit事务。</li>
<li>如果binlog事务不完整，则直接回滚。</li>
</ul>
<h1 id="事务">事务</h1>
<h2 id="事务会出现的问题">事务会出现的问题</h2>
<p>脏读（读取未提交数据）</p>
<p>不可重复读（前后多次读取，数据内容不一致）</p>
<p>幻读（前后多次读取，<strong>数据总量</strong>不一致）</p>
<p>简单给个实例：</p>
<table>
<thead>
<tr>
<th>A</th>
<th>B</th>
</tr>
</thead>
<tbody>
<tr>
<td>start transaction with consistent snapshot</td>
<td></td>
</tr>
<tr>
<td>select * from t0; // 没有id为4的行</td>
<td></td>
</tr>
<tr>
<td></td>
<td>insert into t0(id, k) values(4,4);// 插入成功</td>
</tr>
<tr>
<td>insert into t0(id, k) values(4,4); // 报错了。ERROR 1062 (23000): Duplicate entry &lsquo;4&rsquo; for key &rsquo;t0.PRIMARY&rsquo;</td>
<td></td>
</tr>
<tr>
<td>select * from t0; // 查询的结果和上面一样的，但是插入失败。</td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="事务隔离级别">事务隔离级别</h2>
<h2 id="一个小实验">一个小实验</h2>
<p>有三个事务，trx_a，trx_b，trx_c；</p>
<p><img src="%E4%BA%8B%E5%8A%A1%E7%9A%84%E5%B0%8F%E5%AE%9E%E9%AA%8C%5Ctrx_preview.jpg" alt=""></p>
<p>先说结论：在可重复读的隔离级别下，在trx_b中的select查询的k为3；在trx_a中查询出来的k为1；</p>
<p>现在事务c中更新。</p>
<p><img src="%E4%BA%8B%E5%8A%A1%E7%9A%84%E5%B0%8F%E5%AE%9E%E9%AA%8C%5Ctrx_c.png" alt=""></p>
<p>然后在事务b中更新，其中事务执行的顺序是在事务c更新之前执行的。</p>
<p><img src="%E4%BA%8B%E5%8A%A1%E7%9A%84%E5%B0%8F%E5%AE%9E%E9%AA%8C%5Ctrx_b.png" alt=""></p>
<p>最后在事务a中查询</p>
<p><img src="%E4%BA%8B%E5%8A%A1%E7%9A%84%E5%B0%8F%E5%AE%9E%E9%AA%8C%5Ctrx_a.png" alt=""></p>
<p>可以看出结论是正确的。</p>
<h2 id="事务原理">事务原理</h2>
<p>每个事务有自己的唯一id，叫做transaction_id，在事务开始的时候向innodb申请的，顺序严格递增。</p>
<p>每一行有一个版本，在事务更新的时候，事务会把transaction_id赋值给这行当前的数据版本，就是说每一行会有多个版本，叫做row_trx_id。</p>
<h4 id="事务开始时机">事务开始时机</h4>
<p>begin/start transaction不是执行了之后事务就开始了，而是遇见第一条操作innodb表的语句才开始。</p>
<p>而start transaction with consistent snapshot 是马上就开始一个事务。</p>
<h3 id="undolog">undolog</h3>
<p>undolog就是数据行更新的记录。</p>
<p>要获取之前版本的数据行，是通过最大的row_trx_id版本的数据行+undolog计算出来的。</p>
<h3 id="可重复读的原理">可重复读的原理</h3>
<p>一致性读：在一个事务启动时，能够看见所有<strong>其他已经提交的事务</strong>的结果，但是在事务执行时，只能看见当前版本的数据，其他事务的修改对本事务不影响。</p>
<p>所以上面的事务a的结果为最初的结果。</p>
<p>总结判断一致性读的时机（对上面的那句话的总结）：</p>
<ul>
<li>版本未提交，不可见。</li>
<li>版本已提交，但是在视图创建之后提交的，不可见。</li>
<li>版本已提交，而且是在视图创建时提交的，可见。</li>
</ul>
<p>那为什么事务b查询出来的结果是能够看见事务c更新的结果呢？</p>
<h3 id="当前读">当前读</h3>
<p>更新数据都是先读后写的，这个读是读当前版本。</p>
<p>所以在事务b更新的时候，读取到了事务c提交的版本，后面查询的时候查询的事务b更新之后的版本。</p>
<p>除了update，select加行锁也会触发当前读。</p>
<p><strong>insert不会触发当前读</strong>，也就是插入成功了，只会读取当前事务对表操作的结果，别的事务的insert的结果不会显示出来。</p>
<h1 id="索引">索引</h1>
<h2 id="分类">分类</h2>
<p>分为三种：hashtable、顺序表、b+树。</p>
<h3 id="hashtable">hashtable</h3>
<p>hashtable因为无序所以插入性能比较好，对于等值查询的情况比较好，但是因为无序，对于区间查询则显得比较慢。</p>
<h3 id="顺序表">顺序表</h3>
<p>顺序表（非链表）在因为有序所以在区间查询的条件下表现的比较优秀，但是由于要保证顺序，在插入的时候，开销的比较大需要把元素整体往后挪。</p>
<h3 id="b树">b+树</h3>
<p>b+树的定义是：</p>
<p><strong>1)</strong> 有n棵子树的节点中含有n个关键字(即每个关键字对应一棵子树)；</p>
<p><strong>2)</strong> 所有叶子节点中包含了全部关键字的信息， 及指向含这些关键字记录的指针，且叶子节点本身依关键字的大小自小而大顺序链接；</p>
<p><strong>3)</strong> 所有的非终端节点可以看成是索引部分，节点中仅含有其子树（根节点）中的最大（或最小)关键字</p>
<p><strong>4)</strong> 除根节点外，其他所有节点中所含关键字的个数必须<code>&gt;=⌈m/2⌉</code>(注意： <code>B-树</code>是除根以外的所有非终端节点至少有<code>⌈m/2⌉</code>棵子树)</p>
<p>上面的定义是从网上扒下来的，用大白话说就是：</p>
<ol>
<li>非叶子节点不保存数据，只用来当作索引，真正存储数据的是叶子节点。</li>
<li>每节点都仅含其子节点的最大或者最小的关键字。</li>
<li>叶子节点</li>
<li>在查询的时候，都会查询到叶子节点，而不是查询到某个节点值相等就停下。</li>
</ol>
<p><img src=".%5Cb+%E6%A0%91.png" alt=""></p>
<h2 id="页分裂和页合并">页分裂和页合并</h2>
<p>b+树在插入的时候有算法，那就是会限制一个节点所能持有的最大关键字的个数，则会申请一个内存页，把一部分的数据挪过去。影响了性能和整体空间利用率。</p>
<p>同样的，如果有相邻页面删除了数据，也会触发b+树的平衡把相邻的页数据合并到一页。</p>
<h2 id="回表">回表</h2>
<p>如果语句是 select * from T where ID=500，即主键查询方式，则只需要搜索 ID 这棵B+ 树</p>
<p>如果语句是 select * from T where k=5，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，<strong>再到 ID 索引树搜索一次</strong>。这个过程称为<strong>回表</strong>。</p>
<h2 id="覆盖索引">覆盖索引</h2>
<p>有一个表person index:(primary_key: id) (id_card,name) (name,age)</p>
<table>
<thead>
<tr>
<th>id</th>
<th>id_card</th>
<th>name</th>
<th>age</th>
<th>ismale</th>
</tr>
</thead>
</table>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">select</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">from</span> person <span style="color:#66d9ef">where</span> age <span style="color:#66d9ef">between</span> <span style="color:#ae81ff">10</span> <span style="color:#66d9ef">and</span> <span style="color:#ae81ff">30</span>;
</span></span></code></pre></div><p>这样会有回表的情况，而直接查询主键，就不会造成回表的情况。因为在查询索引时已经确认了目标字段。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">select</span> id <span style="color:#66d9ef">from</span> person <span style="color:#66d9ef">where</span> age <span style="color:#66d9ef">between</span> <span style="color:#ae81ff">10</span> <span style="color:#66d9ef">and</span> <span style="color:#ae81ff">30</span>;
</span></span></code></pre></div><p>不光主键，只要是在查询的时候涉及到目标字段就能实现索引覆盖。在上面设置了一个组合索引（id_card,name)，这样也不会回表。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">select</span> id_card <span style="color:#66d9ef">from</span> person <span style="color:#66d9ef">where</span> name <span style="color:#66d9ef">like</span> <span style="color:#e6db74">&#39;Jecky%&#39;</span>;
</span></span></code></pre></div><h2 id="最左前缀匹配原则">最左前缀匹配原则</h2>
<p>复合索引如何节省索引个数呢？</p>
<p>先说结论：</p>
<p>b+树可以用最左前缀匹配原则来定位记录，最左前缀可以是字符串索引的最左m个字符，也可以是复合索引的最左n个字段。</p>
<p>如上面的（name,age)复合索引，在下面查询语句中，也可以使用到这个索引，最左边的字段再加上字符串索引的最左n个字符。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">select</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">from</span> person <span style="color:#66d9ef">where</span> name <span style="color:#66d9ef">like</span> <span style="color:#e6db74">&#39;Jecky%&#39;</span>;
</span></span></code></pre></div><p>所以当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了。</p>
<p>但是如果查询语句中只有一个age是不能触发索引的。因为需要加上name查询条件才能走索引。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">select</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">from</span> person <span style="color:#66d9ef">where</span> age <span style="color:#66d9ef">between</span> <span style="color:#ae81ff">10</span> <span style="color:#66d9ef">and</span> <span style="color:#ae81ff">30</span>;
</span></span></code></pre></div><p>此时可以给age新建一个单独的索引。</p>
<p>如果一张表有一个联合索引(a,b,c)，则如果查询condition只有a c或者b c是不能走索引的，因为最左匹配要<strong>匹配最左边所有的</strong></p>
<h2 id="索引下推">索引下推</h2>
<p>在回表之前可以根据条件筛选掉一部分数据，避免回表的数据比较多。</p>
<p>例如：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sql" data-lang="sql"><span style="display:flex;"><span><span style="color:#66d9ef">select</span> <span style="color:#f92672">*</span> <span style="color:#66d9ef">from</span> person <span style="color:#66d9ef">where</span> name <span style="color:#66d9ef">like</span> <span style="color:#e6db74">&#39;Jecky%&#39;</span> <span style="color:#66d9ef">and</span> age <span style="color:#66d9ef">between</span> <span style="color:#ae81ff">10</span> <span style="color:#66d9ef">and</span> <span style="color:#ae81ff">30</span>;
</span></span></code></pre></div><p>使用索引查询出以jecky为前缀的，并且在非主键b+树中筛选掉了age在10-30之间的，<strong>只会让那些已经满足该条件的记录回表</strong>。</p>
<h1 id="锁">锁</h1>
<h2 id="表锁">表锁</h2>
<h4 id="读写锁">读写锁</h4>
<p>lock table &hellip; read/write</p>
<p>读锁与读锁之间没有冲突，但是加了读锁之后其他线程加写锁会卡住。</p>
<p>加了写锁，其他线程的读和写锁就都会锁定。</p>
<p>同时一个线程加了读锁，在unlock table之前只能读该表。</p>
<h3 id="mdl">mdl</h3>
<p>在<strong>修改表结构</strong>的时候加的锁，也分为读锁和写锁。读锁之间不互斥，因此可以有多个线程同时对一张表增删改查。</p>
<p>所有对表的增删改查操作都需要先申请MDL 读锁。</p>
<p>但是mdl写锁加了之后，其他线程在进行增删改查的时候申请mdl读锁也会卡住。</p>
<h2 id="行锁">行锁</h2>
<h3 id="两段锁协议">两段锁协议</h3>
<p>在innodb事务中，对一行加的锁不是在写完这一行结束之后就释放，而是在事务结束的时候才会释放。</p>
<p>行锁可能会造成死锁，a和b两个线程开启了事务，并且都持有了对方要锁的记录，就会造成死锁。</p>
<h1 id="change-buffer">change buffer</h1>
<p>在<a href="#%E4%B8%A4%E9%98%B6%E6%AE%B5%E5%86%99">两阶段写</a>中描述了更新的过程，还省略了change buffer的内容。</p>
<p><strong>下面的内容存疑，为自己的理解</strong></p>
<p><strong>&mdash;&mdash;&mdash;&ndash;分割线&mdash;&mdash;&mdash;&mdash;-</strong></p>
<p>在<a href="#%E4%B8%A4%E9%98%B6%E6%AE%B5%E5%86%99">两阶段写</a>中，说更新的时候innodb会看内存是否存放了数据页，如果没有就从磁盘加载。</p>
<p>我理解是不会从磁盘加载，而是将写操作写入change buffer，再执行下一步。</p>
<p>那后面执行器怎么能够拿到的这一行数据呢？我的理解是，不是在执行器这一层进行的更新，而是在引擎层进行的更新。</p>
<p>这样就能在更新的时候，把更新记录写入change buffer和redolog。</p>
<p>然后再开启两阶段写。</p>
<p><strong>&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&mdash;&ndash;</strong></p>
<p>如果是普通索引，在执行写操作的时候，并且不影响数据一致性的前提下，写操作会被缓存在change buffer中，等待下次该数据页被写入内存的时候再去更新该记录所在的数据页。</p>
<p>而如果是唯一索引，在写操作的时候，需要判断新增的数据是否唯一，需要把数据页都加入到内存中才能判断，此时直接在内存当中执行写操作会更快而不用写入change buffer。</p>
<h2 id="change-buffer和redolog">change buffer和redolog</h2>
<p>假设插入2条数据，并且update的condition是普通索引。</p>
<ol>
<li>将新的记录写入change buffer。</li>
<li>redolog记录下，把数据写入了change buffer这个操作。</li>
</ol>
<h1 id="优化器的逻辑">优化器的逻辑</h1>
<p>优化器会找出一个最小的代价的方案执行语句。和扫描行数、临时表、是否排序有关。</p>
<h2 id="扫描行数是怎么判断的">扫描行数是怎么判断的？</h2>
<p>和<code>Cardinality</code>有关系，这个值被称作基数，指的是索引上不同值的个数。基数越大，区分度越好。</p>
<p>innodb不可能把所有的数据都统计一遍，其统计做法是，随机取n个数据页，求这几个数据页的基数的平均值。当变更的数据行数超过了1/m行，会重新触发采样统计。</p>
<p>可以通过一个参数：innodb_stats_persistent 来控制n和m的大小（只能选择两种方案，无法自定义）。</p>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://kyriexu11.github.io/" >
    &copy;  Secret Room of KyrieXu11 2022 
  </a>
    <div>
<div class="ananke-socials">
  
</div>
</div>
  </div>
</footer>

  </body>
</html>
