# 执行结构

总体分为两个部分：

server 和 执行引擎

## server

连接器->分析器->优化器->执行器。

连接器：负责管理连接。超时断开、用户密码校验。

分析器：词法分析。

优化器：优化查询。

执行器：执行语句，权限校验。

## 执行引擎

常见的有innodb和myaism。

# redolog和binlog

## redolog

redolog为innodb实现的。

对数据库做的更新操作不直接写入磁盘，而是通过write ahead log的技术写入redolog。在空闲的时候，把redolog中的改动同步到磁盘。

图源：https://blog.csdn.net/weixin_43213517/article/details/117457184

![innodb_redolog](.\innodb_redolog.png)

### 为什么需要redolog？

innodb是以页的方式来管理存储空间的，在进行增删改的时候，需要把记录所在的整个页加载到buffer pool（内存）中，在内存做完写操作之后，再进行刷盘，刷盘为随机IO，开销太大。

### redolog如何持久化

#### 刷盘时机

1. 后台定时刷盘。
2. 用户commit时。

#### 两个指针

write position和checkpoint。

redolog为环形log，当wp追上了checkpoint，就要刷盘了，这个时候把checkpoint往前推进，才可以继续写。

## binlog

binlog为server的日志，不归属任何执行引擎，所有执行引擎都可以用。

和redolog有几点不同：

1. binlog为逻辑日志，而redolog为物理日志。binlog会记录下“给哪一行更新id=2”，而redolog会记录下“在哪个数据页的哪一行进行修改”。
2. redolog循环写，空间会用完，binlog为追加写，理论上无限大。

## 两阶段写

总体和分布式事务一个思想，以更新为例子：

1. 执行器找执行引擎取目标记录，执行引擎用树来找这一条记录，如果在内存则直接返回，如果不在内存，则将该记录所在的整个页加载到内存，再返回。
2. 执行器在内存更新完成该记录，再调用引擎的接口写入这行数据。
3. 执行引擎在内存中更新这条数据，并且把更新记录写入redolog，把redolog的状态置为prepare状态，并且告知执行器可以写binlog。
4. 执行器写binlog，把binlog写入磁盘。
5. 执行器再调用执行引擎的接口把redolog的状态改为commit。

如果在写的时候出现的crash，该怎么恢复？

1. 如果redolog中的事务是完整的（有commit标识），则直接commit。
2. 如果redolog只有prepare，则去看binlog事务是否完整。
  + 如果binlog存在事务并且完整，则改redolog为commit，然后commit事务。
  + 如果binlog事务不完整，则直接回滚。

# 事务

## 事务会出现的问题

脏读（读取未提交数据）

不可重复读（前后多次读取，数据内容不一致）

幻读（前后多次读取，**数据总量**不一致）

简单给个实例：

| A                                                            | B                                             |
| ------------------------------------------------------------ | --------------------------------------------- |
| start transaction with consistent snapshot                   |                                               |
| select * from t0; // 没有id为4的行                           |                                               |
|                                                              | insert into t0(id, k) values(4,4);// 插入成功 |
| insert into t0(id, k) values(4,4); // 报错了。ERROR 1062 (23000): Duplicate entry '4' for key 't0.PRIMARY' |                                               |
| select * from t0; // 查询的结果和上面一样的，但是插入失败。  |                                               |



## 事务隔离级别





## 一个小实验

有三个事务，trx_a，trx_b，trx_c；

![](事务的小实验\trx_preview.jpg)

先说结论：在可重复读的隔离级别下，在trx_b中的select查询的k为3；在trx_a中查询出来的k为1；

现在事务c中更新。

![](事务的小实验\trx_c.png)

然后在事务b中更新，其中事务执行的顺序是在事务c更新之前执行的。

![](事务的小实验\trx_b.png)

最后在事务a中查询

![](事务的小实验\trx_a.png)

可以看出结论是正确的。

## 事务原理

每个事务有自己的唯一id，叫做transaction_id，在事务开始的时候向innodb申请的，顺序严格递增。

每一行有一个版本，在事务更新的时候，事务会把transaction_id赋值给这行当前的数据版本，就是说每一行会有多个版本，叫做row_trx_id。

#### 事务开始时机

begin/start transaction不是执行了之后事务就开始了，而是遇见第一条操作innodb表的语句才开始。

而start transaction with consistent snapshot 是马上就开始一个事务。

### undolog

undolog就是数据行更新的记录。

要获取之前版本的数据行，是通过最大的row_trx_id版本的数据行+undolog计算出来的。

### 可重复读的原理

一致性读：在一个事务启动时，能够看见所有**其他已经提交的事务**的结果，但是在事务执行时，只能看见当前版本的数据，其他事务的修改对本事务不影响。

所以上面的事务a的结果为最初的结果。

总结判断一致性读的时机（对上面的那句话的总结）：

* 版本未提交，不可见。
* 版本已提交，但是在视图创建之后提交的，不可见。
* 版本已提交，而且是在视图创建时提交的，可见。



那为什么事务b查询出来的结果是能够看见事务c更新的结果呢？

### 当前读

更新数据都是先读后写的，这个读是读当前版本。

所以在事务b更新的时候，读取到了事务c提交的版本，后面查询的时候查询的事务b更新之后的版本。

除了update，select加行锁也会触发当前读。

**insert不会触发当前读**，也就是插入成功了，只会读取当前事务对表操作的结果，别的事务的insert的结果不会显示出来。

# 索引

## 分类

分为三种：hashtable、顺序表、b+树。

### hashtable

hashtable因为无序所以插入性能比较好，对于等值查询的情况比较好，但是因为无序，对于区间查询则显得比较慢。

### 顺序表

顺序表（非链表）在因为有序所以在区间查询的条件下表现的比较优秀，但是由于要保证顺序，在插入的时候，开销的比较大需要把元素整体往后挪。

### b+树

b+树的定义是：

**1)** 有n棵子树的节点中含有n个关键字(即每个关键字对应一棵子树)；

**2)** 所有叶子节点中包含了全部关键字的信息， 及指向含这些关键字记录的指针，且叶子节点本身依关键字的大小自小而大顺序链接；

**3)** 所有的非终端节点可以看成是索引部分，节点中仅含有其子树（根节点）中的最大（或最小)关键字

**4)** 除根节点外，其他所有节点中所含关键字的个数必须`>=⌈m/2⌉`(注意： `B-树`是除根以外的所有非终端节点至少有`⌈m/2⌉`棵子树)

上面的定义是从网上扒下来的，用大白话说就是：

1. 非叶子节点不保存数据，只用来当作索引，真正存储数据的是叶子节点。
2. 每节点都仅含其子节点的最大或者最小的关键字。
3. 叶子节点
4. 在查询的时候，都会查询到叶子节点，而不是查询到某个节点值相等就停下。

![](.\b+树.png)

## 页分裂和页合并

b+树在插入的时候有算法，那就是会限制一个节点所能持有的最大关键字的个数，则会申请一个内存页，把一部分的数据挪过去。影响了性能和整体空间利用率。

同样的，如果有相邻页面删除了数据，也会触发b+树的平衡把相邻的页数据合并到一页。

## 回表

如果语句是 select * from T where ID=500，即主键查询方式，则只需要搜索 ID 这棵B+ 树

如果语句是 select * from T where k=5，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，**再到 ID 索引树搜索一次**。这个过程称为**回表**。

## 覆盖索引

有一个表person index:(primary_key: id) (id_card,name) (name,age)

| id   | id_card | name | age  | ismale |
| ---- | ------- | ---- | ---- | ------ |

```sql
select * from person where age between 10 and 30;
```

这样会有回表的情况，而直接查询主键，就不会造成回表的情况。因为在查询索引时已经确认了目标字段。

```sql
select id from person where age between 10 and 30;
```

不光主键，只要是在查询的时候涉及到目标字段就能实现索引覆盖。在上面设置了一个组合索引（id_card,name)，这样也不会回表。

```sql
select id_card from person where name like 'Jecky%';
```



## 最左前缀匹配原则

复合索引如何节省索引个数呢？

先说结论：

b+树可以用最左前缀匹配原则来定位记录，最左前缀可以是字符串索引的最左m个字符，也可以是复合索引的最左n个字段。

如上面的（name,age)复合索引，在下面查询语句中，也可以使用到这个索引，最左边的字段再加上字符串索引的最左n个字符。

```sql
select * from person where name like 'Jecky%';
```

所以当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了。

但是如果查询语句中只有一个age是不能触发索引的。因为需要加上name查询条件才能走索引。

```sql
select * from person where age between 10 and 30;
```

此时可以给age新建一个单独的索引。

如果一张表有一个联合索引(a,b,c)，则如果查询condition只有a c或者b c是不能走索引的，因为最左匹配要**匹配最左边所有的**



## 索引下推

在回表之前可以根据条件筛选掉一部分数据，避免回表的数据比较多。

例如：

```sql
select * from person where name like 'Jecky%' and age between 10 and 30;
```

使用索引查询出以jecky为前缀的，并且在非主键b+树中筛选掉了age在10-30之间的，**只会让那些已经满足该条件的记录回表**。

# 锁

## 表锁

#### 读写锁

lock table ... read/write

读锁与读锁之间没有冲突，但是加了读锁之后其他线程加写锁会卡住。

加了写锁，其他线程的读和写锁就都会锁定。

同时一个线程加了读锁，在unlock table之前只能读该表。

### mdl

在**修改表结构**的时候加的锁，也分为读锁和写锁。读锁之间不互斥，因此可以有多个线程同时对一张表增删改查。

所有对表的增删改查操作都需要先申请MDL 读锁。

但是mdl写锁加了之后，其他线程在进行增删改查的时候申请mdl读锁也会卡住。

## 行锁

### 两段锁协议

在innodb事务中，对一行加的锁不是在写完这一行结束之后就释放，而是在事务结束的时候才会释放。

行锁可能会造成死锁，a和b两个线程开启了事务，并且都持有了对方要锁的记录，就会造成死锁。

# change buffer

在[两阶段写](#两阶段写)中描述了更新的过程，还省略了change buffer的内容。

**下面的内容存疑，为自己的理解**

**-----------分割线-------------**

在[两阶段写](#两阶段写)中，说更新的时候innodb会看内存是否存放了数据页，如果没有就从磁盘加载。

我理解是不会从磁盘加载，而是将写操作写入change buffer，再执行下一步。

那后面执行器怎么能够拿到的这一行数据呢？我的理解是，不是在执行器这一层进行的更新，而是在引擎层进行的更新。

这样就能在更新的时候，把更新记录写入change buffer和redolog。

然后再开启两阶段写。

**-----------------------------------**



如果是普通索引，在执行写操作的时候，并且不影响数据一致性的前提下，写操作会被缓存在change buffer中，等待下次该数据页被写入内存的时候再去更新该记录所在的数据页。

而如果是唯一索引，在写操作的时候，需要判断新增的数据是否唯一，需要把数据页都加入到内存中才能判断，此时直接在内存当中执行写操作会更快而不用写入change buffer。

## change buffer和redolog

假设插入2条数据，并且update的condition是普通索引。

1. 将新的记录写入change buffer。
2. redolog记录下，把数据写入了change buffer这个操作。



# 优化器的逻辑

优化器会找出一个最小的代价的方案执行语句。和扫描行数、临时表、是否排序有关。

## 扫描行数是怎么判断的？

和`Cardinality`有关系，这个值被称作基数，指的是索引上不同值的个数。基数越大，区分度越好。

innodb不可能把所有的数据都统计一遍，其统计做法是，随机取n个数据页，求这几个数据页的基数的平均值。当变更的数据行数超过了1/m行，会重新触发采样统计。

可以通过一个参数：innodb_stats_persistent 来控制n和m的大小（只能选择两种方案，无法自定义）。

